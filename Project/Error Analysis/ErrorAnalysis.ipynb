{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import csv\n",
    "import json\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sn\n",
    "from sklearn.metrics import roc_auc_score\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ground Truth Predictions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid = pd.read_json(\"/home/aditya/Documents/CS 626/Project1/Detection-of-Hate-Speech-in-Multimodal-Memes-main/Error Analysis/dev_seen.jsonl\", lines=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ground truth labels\n",
    "actual = {valid['id'][i]:valid['label'][i] for i in range(500)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid.set_index(\"id\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Helper Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Returns True Positives, False Positives, True Negatives, False Negatives, AUROC_score\n",
    "'''\n",
    "def Statistics(actual, pred_labels, pred_prob, sorted_dict):\n",
    "    \n",
    "    #Correctly Predicted\n",
    "    True_positives = defaultdict(int)\n",
    "    True_negatives = defaultdict(int)\n",
    "\n",
    "\n",
    "    #Benign Meme but predicted hateful\n",
    "    False_positives = defaultdict(int)\n",
    "\n",
    "    # Hateful Meme, but predicted Benign\n",
    "    False_negatives = defaultdict(int)\n",
    "\n",
    "\n",
    "\n",
    "    for ids in list(actual.keys()):\n",
    "\n",
    "        if actual[ids] != pred_labels[ids]:\n",
    "\n",
    "            if pred_prob[ids]>=0.5:\n",
    "                False_positives[ids] = pred_prob[ids]\n",
    "\n",
    "            else:\n",
    "                 False_negatives[ids] = pred_prob[ids]   \n",
    "\n",
    "\n",
    "        else:\n",
    "            if pred_prob[ids]>=0.5:\n",
    "                True_positives[ids] = pred_prob[ids]\n",
    "\n",
    "            else:\n",
    "                 True_negatives[ids] = pred_prob[ids]   \n",
    "            \n",
    "        \n",
    "    return sorted_dict(True_positives), sorted_dict(True_negatives), sorted_dict(False_positives),  sorted_dict(False_negatives)\n",
    "     \n",
    "\n",
    "    \n",
    "\n",
    "'''\n",
    "Get count of True Positives, False Positives, True Negatives, False Negatives\n",
    "'''\n",
    "def count(True_positives, True_negatives, False_positives,  False_negatives):\n",
    "    \n",
    "    tp = len(True_positives)\n",
    "    tn = len(True_negatives)\n",
    "    fp = len(False_positives)\n",
    "    fn = len(False_negatives)\n",
    "    total = tp+tn+fp+fn\n",
    "    \n",
    "    return tp,tn,fp,fn,total\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "Plots Confusion Matrix\n",
    "'''\n",
    "def plot_confusion_matrix(tn, fp, fn, tp, AUROC_score,total):\n",
    "    \n",
    "    \n",
    "    matrix = np.array(([tn, fp],[fn,tp]))\n",
    "    percent = (matrix/matrix.sum())*100\n",
    "    \n",
    "    accuracy = ((tp+tn)/total)*100\n",
    "    Precision = (tp/(tp+fp))*100\n",
    "    Recall = (tp/(tp+fn))*100\n",
    "    F1_score =  2 * (Precision * Recall) / (Precision + Recall)\n",
    "    \n",
    "    \n",
    "    df_cm = pd.DataFrame(matrix, ['Benign','Hateful'], ['Benign','Hateful'])\n",
    "    text = np.asarray([['True Negatives', 'False Positives'], ['False Negatives', 'True Positives']])\n",
    "    label = (np.asarray([\"{0}\\n\\n{1}\\n\\n{2: .2f}%\".format(text,matrix,percent) for text, matrix, percent in zip(text.flatten(), matrix.flatten(), percent.flatten())])).reshape(2,2)\n",
    "    \n",
    "    plt.figure(figsize=(10,10))\n",
    "    sn.set(font_scale=2)\n",
    "    sn.heatmap(df_cm, annot=label, annot_kws={\"size\": 20}, cbar_kws={'label':\"Memes\"}, fmt ='', cmap ='Blues')\n",
    "    \n",
    "    plt.title('Confusion Matrix', fontsize=20)\n",
    "    plt.text(0.1, 2.5, 'Precision: '+str(round(Precision,2)) + '        Recall: '+str(round(Recall,2))+'     F1 Score: '+str(round(F1_score,2))+\n",
    "            '\\n\\nAccuracy: '+ str(round(accuracy,2))+'          AUROC:'+ str(round(AUROC_score,2)), fontsize=20)\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "'''\n",
    "Get AUROC score using sklearn.metrics.roc_auc_score\n",
    "'''\n",
    "def get_AUROC(actual, pred_labels):\n",
    "    \n",
    "    ytrue=[]\n",
    "    ypred=[]\n",
    "    for ids in list(actual.keys()):\n",
    "        ytrue.append(actual[ids])\n",
    "        ypred.append(pred_labels[ids])\n",
    "\n",
    "    AUROC_score = roc_auc_score(ytrue, ypred)\n",
    "    \n",
    "    return AUROC_score\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "Return a Dictionary by it's values sorted in descending order\n",
    "'''\n",
    "def sorted_dict(unsorted_dictionary):\n",
    "    sorted_keys = sorted(unsorted_dictionary, key =unsorted_dictionary.__getitem__, reverse=True)\n",
    "\n",
    "    sorted_values = sorted(unsorted_dictionary.values(),reverse=True)\n",
    "\n",
    "    sorted_dictionary = {}\n",
    "    for i in range(len(sorted_keys)):\n",
    "        sorted_dictionary[sorted_keys[i]] = sorted_values[i]\n",
    "        \n",
    "    return sorted_dictionary\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "Display a Image\n",
    "'''\n",
    "def open_image(path, actual, pred_labels, pred_prob):\n",
    "    label_dict = {0:'Benign', 1:'Hateful'}\n",
    "\n",
    "    ground_truth = label_dict[actual[image_id]]\n",
    "    predicted_label = label_dict[pred_labels[image_id]]\n",
    "    confidence = pred_prob[image_id]\n",
    "    \n",
    "    image = Image.open('data/'+path)\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.axis('off')\n",
    "    plt.rcParams[\"axes.grid\"] = False\n",
    "    plt.text(0,image.size[1]+25, 'Annotated label: '+ ground_truth+ '       Predicted label: '+ predicted_label+ '       Probability: '+ str(round(confidence,4)), fontsize=15)\n",
    "    plt.imshow(image)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analysis of Visual BERT COCO on Validation set**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Predicted labels**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = pd.read_csv('hateful_memes_run_val_2020-11-13T02_20_30.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "predicted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicted Labels\n",
    "pred_labels = {predicted['id'][i]:predicted['label'][i] for i in range(500)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicted Probabilities\n",
    "pred_prob = {predicted['id'][i]:predicted['proba'][i] for i in range(500)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "True_positives, True_negatives, False_positives,  False_negatives =  Statistics(actual, pred_labels, pred_prob, sorted_dict)\n",
    "\n",
    "tp,tn,fp,fn,total = count(True_positives, True_negatives, False_positives,  False_negatives)\n",
    "\n",
    "AUROC_score = get_AUROC(actual, pred_labels)\n",
    "\n",
    "plot_confusion_matrix(tn, fp, fn, tp, AUROC_score, total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# True Positive with Highest Confidence (Hateful Meme predicted as Hateful)\n",
    "\n",
    "path = valid.loc[list(True_positives.keys())[0]]['img']\n",
    "image_id = list(True_positives.keys())[0]\n",
    "open_image(path, actual, pred_labels, pred_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# True Negative with Highest Confidence (Benign meme predicted as Benign)\n",
    "path = valid.loc[list(True_negatives.keys())[-3]]['img']\n",
    "image_id = list(True_negatives.keys())[-3]\n",
    "\n",
    "open_image(path, actual, pred_labels, pred_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# False Positive with Highest Confidence (Benign meme prediced as Hateful)\n",
    "path = valid.loc[list(False_positives.keys())[0]]['img']\n",
    "image_id = list(False_positives.keys())[0]\n",
    "open_image(path, actual, pred_labels, pred_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# False Negative with Highest Confidence (Hateful Meme predicted as Benign)\n",
    "path = valid.loc[list(False_negatives.keys())[-1]]['img']\n",
    "image_id = list(False_negatives.keys())[-1]\n",
    "open_image(path, actual, pred_labels, pred_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analysis of VilBERT CC on Validation set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = pd.read_csv('hateful_memes_run_val_2020-11-14T00_33_22.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicted Labels\n",
    "pred_labels = {predicted['id'][i]:predicted['label'][i] for i in range(500)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicted Probabilities\n",
    "pred_prob = {predicted['id'][i]:predicted['proba'][i] for i in range(500)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "True_positives, True_negatives, False_positives,  False_negatives =  Statistics(actual, pred_labels, pred_prob, sorted_dict)\n",
    "\n",
    "tp,tn,fp,fn,total = count(True_positives, True_negatives, False_positives,  False_negatives)\n",
    "\n",
    "AUROC_score = get_AUROC(actual, pred_labels)\n",
    "\n",
    "plot_confusion_matrix(tn, fp, fn, tp, AUROC_score, total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# True Positive with Highest Confidence (Hateful Meme predicted as Hateful)\n",
    "\n",
    "path = valid.loc[list(True_positives.keys())[3]]['img']\n",
    "image_id = list(True_positives.keys())[3]\n",
    "open_image(path, actual, pred_labels, pred_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# True Negative with Highest Confidence (Benign meme predicted as Benign)\n",
    "path = valid.loc[list(True_negatives.keys())[-1]]['img']\n",
    "image_id = list(True_negatives.keys())[-1]\n",
    "open_image(path, actual, pred_labels, pred_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# False Positive with Highest Confidence (Benign meme prediced as Hateful)\n",
    "path = valid.loc[list(False_positives.keys())[4]]['img']\n",
    "image_id = list(False_positives.keys())[4]\n",
    "open_image(path, actual, pred_labels, pred_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# False Negative with Highest Confidence (Hateful Meme predicted as Benign)\n",
    "path = valid.loc[list(False_negatives.keys())[-7]]['img']\n",
    "image_id = list(False_negatives.keys())[-7]\n",
    "open_image(path, actual, pred_labels, pred_prob)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
